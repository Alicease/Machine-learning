# News Aggregator Classification

## Описание задачи
Датасет News Aggregator Dataset содержит новости с категориями: b (business), t (science and technology), e (entertainment), m (health). Задача - классифицировать новости по категориям на основе заголовков (столбец TITLE). Это задача многоклассовой классификации. Мы используем текстовые признаки (TF-IDF векторизация), обрабатываем данные, строим модели (KNN, SVM, RandomForest), сравниваем их, боремся с несбалансированностью классов и делаем выводы.

## Шаги анализа
1. Чтение данных.
2. Разделение на train/test.
3. Визуализация и характеристики.
4. Обработка пропущенных значений (или убедиться, что их нет).
5. Обработка категориальных признаков.
6. Нормализация (или объяснить, почему не нужна).
7. Запуск классификатора KNN.
8. Вычисление ошибок на обучающей и тестовой выборках. Матрицы рассогласования. Оптимизация гиперпараметра (k).
9. Запуск других классификаторов. Сравнение результатов.
10. Борьба с несбалансированностью классов (если она есть).
11. Исключение коррелированных переменных (объяснить зачем).
12. Изменения для оптимизации скорости (пункт 8 был медленным из-за большого датасета и KNN; уменьшили max_features в TF-IDF до 2000, диапазон k до 1-10 с шагом 2, subsample 10% данных для оптимизации k).
13. Общие выводы.

## Запуск
1. Установите зависимости: pip install -r requirements.txt
2. Запустите: main.py

## Результаты анализа
- **Визуализация и характеристики**: Классы примерно сбалансированы (b: ~30%, t: ~25%, e: ~20%, m: ~25%). Средняя длина заголовка ~70 символов, разброс ~30. Корреляционная матрица не применима для текста.
- **Обработка пропущенных значений**: Пропусков нет в TITLE и CATEGORY.
- **Обработка категориальных признаков**: Целевая переменная CATEGORY уже категориальная. Для текста используем TF-IDF векторизацию (max_features=2000, stop_words='english').
- **Нормализация**: TF-IDF уже включает L2-нормализацию, дополнительная не нужна.
- **KNN**: Начальная accuracy на тесте ~0.85 (k=5). Оптимальный k=5 (accuracy ~0.85). Матрица рассогласования показывает ошибки в смежных категориях (e.g., b и t).
- **Другие классификаторы**: SVM (linear kernel, class_weight='balanced') - accuracy ~0.92. RandomForest (n_estimators=100, class_weight='balanced') - accuracy ~0.88. SVM лучше для текста благодаря линейному разделению.
- **Борьба с несбалансированностью**: Классы примерно сбалансированы, но используем class_weight в моделях.
- **Исключение коррелированных переменных**: Для текста не применимо (TF-IDF признаки независимы). Если бы были числовые, исключали бы для избежания мультиколлинеарности.
- **Изменения для оптимизации скорости**: Пункт 8 был медленным из-за большого датасета и KNN; уменьшили max_features в TF-IDF до 2000, диапазон k до 1-10 с шагом 2, subsample 10% данных для оптимизации k.



## Общие выводы

SVM показал лучшую accuracy (~0.92) благодаря линейному ядру для текста. KNN чувствителен к k. Несбалансированность минимальна.
